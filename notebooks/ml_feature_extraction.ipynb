{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29033f42-0e0d-43da-b833-73322b5253b3",
   "metadata": {},
   "source": [
    "# **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ab4e8e28-c3b0-41e6-a49d-b097034af57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ca3145-9523-4e42-bc6b-045d4895090e",
   "metadata": {},
   "source": [
    "- **numpy** → numerical arrays for ML\n",
    "- **librosa** → audio feature extraction\n",
    "- **soundfile** → stable audio loading (faster & safer than librosa.load)\n",
    "- **Path** → OS-independent file traversal\n",
    "- **tqdm** → progress bar (important for large datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de64199-6b1a-4a07-b5b6-6e08b4b5efa2",
   "metadata": {},
   "source": [
    "# **Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e939e98d-1053-4790-bfad-abdfd76fafb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(\"../data\")\n",
    "\n",
    "LABEL_MAP = {\n",
    "    \"AI\": 0,\n",
    "    \"Human\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11435826-11f6-4812-bfa5-ecb522384632",
   "metadata": {},
   "source": [
    "# **Audio Loading**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f72891a-be71-47d2-acec-a2c021bb9c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_audio(path, target_sr=16000):\n",
    "    y, sr = sf.read(path)\n",
    "\n",
    "    # Convert stereo to mono\n",
    "    if y.ndim > 1:\n",
    "        y = y.mean(axis=1)\n",
    "\n",
    "    # Resample if needed\n",
    "    if sr != target_sr:\n",
    "        y = librosa.resample(y, orig_sr=sr, target_sr=target_sr)\n",
    "\n",
    "    # Normalize amplitude\n",
    "    y = librosa.util.normalize(y)\n",
    "\n",
    "    return y, target_sr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24941fb-bb46-40ca-a620-d3df5ad9f1d4",
   "metadata": {},
   "source": [
    "- **Converts all audio to mono**\n",
    "- **Resamples to 16 kHz (industry standard for speech)**\n",
    "- **Normalization removes loudness bias**\n",
    "- **Ensures every sample is comparable**\n",
    "\n",
    "**This prevents the model from cheating.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dec7c9-55c3-4227-bda0-a7478db8f35b",
   "metadata": {},
   "source": [
    "# **Feature Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3fdeab94-8de4-481b-b7fc-b468c49285e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(y, sr):\n",
    "    # Mel spectrogram\n",
    "    mel = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=sr // 2)\n",
    "    \n",
    "    mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "    \n",
    "    mel_mean = np.mean(mel_db, axis=1)\n",
    "    mel_std = np.std(mel_db, axis=1)\n",
    "\n",
    "    # MFCC\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
    "    \n",
    "    mfcc_mean = np.mean(mfcc, axis=1)\n",
    "    mfcc_std = np.std(mfcc, axis=1)\n",
    "\n",
    "    features = np.concatenate([mel_mean, mel_std, mfcc_mean, mfcc_std])\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340afa84-313d-41a3-a40c-1af372c342da",
   "metadata": {},
   "source": [
    "- **Mel spectrogram captures Human Auditory Perception**\n",
    "- **AI voices often show:**\n",
    "    - **unnatural spectral smoothness**\n",
    "    - **reduced variance**\n",
    "- We aggregate using **mean + std**\n",
    "- Output is a **fixed-length vector**, perfect for ML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bea96e4-5631-4df3-b8e7-2a3151e0d06c",
   "metadata": {},
   "source": [
    "# **Dataset Traversal & Feature Collection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d944c68-038e-41a8-b3bb-4b3181cda023",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Human-English: 100%|██████████| 200/200 [00:08<00:00, 22.74it/s]\n",
      "Human-Hindi: 100%|██████████| 200/200 [00:06<00:00, 30.43it/s]\n",
      "Human-Malayalam: 100%|██████████| 200/200 [00:05<00:00, 33.99it/s]\n",
      "Human-Tamil: 100%|██████████| 200/200 [00:06<00:00, 31.22it/s]\n",
      "Human-Telugu: 100%|██████████| 200/200 [00:06<00:00, 31.29it/s]\n",
      "AI-English: 100%|██████████| 200/200 [00:03<00:00, 65.00it/s]\n",
      "AI-Hindi: 100%|██████████| 200/200 [00:03<00:00, 57.96it/s]\n",
      "AI-Malayalam: 100%|██████████| 200/200 [00:03<00:00, 58.22it/s]\n",
      "AI-Tamil: 100%|██████████| 200/200 [00:03<00:00, 55.25it/s]\n",
      "AI-Telugu: 100%|██████████| 200/200 [00:03<00:00, 56.30it/s]\n"
     ]
    }
   ],
   "source": [
    "X = []\n",
    "y = []\n",
    "languages = []\n",
    "\n",
    "for label_name in [\"Human\", \"AI\"]:\n",
    "    label_value = LABEL_MAP[label_name]\n",
    "    label_dir = DATA_ROOT / label_name\n",
    "\n",
    "    for lang_dir in label_dir.iterdir():\n",
    "        if not lang_dir.is_dir():\n",
    "            continue\n",
    "\n",
    "        language = lang_dir.name\n",
    "\n",
    "        for audio_file in tqdm(list(lang_dir.glob(\"*.mp3\")), desc=f\"{label_name}-{language}\"):\n",
    "\n",
    "            try:\n",
    "                audio, sr = load_audio(audio_file)\n",
    "                features = extract_features(audio, sr)\n",
    "\n",
    "                assert features.shape[0] == 282\n",
    "\n",
    "                X.append(features)\n",
    "                y.append(label_value)\n",
    "                languages.append(language)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Failed on {audio_file}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7b73d4-402c-45d3-b732-0dd3c37b46fa",
   "metadata": {},
   "source": [
    "**Stores:**\n",
    "- **X** → Numerical Features\n",
    "- **y** → Class Label\n",
    "- **languages** → Language Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "66b5d0ec-1891-46d5-a32d-21c41548bf94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Matrix Shape: (2000, 282)\n",
      "Labels Shape: (2000,)\n",
      "Languages Shape: (2000,)\n",
      "AI Samples: 1000\n",
      "Human Samples: 1000\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "languages = np.array(languages)\n",
    "\n",
    "print(\"Feature Matrix Shape:\", X.shape)\n",
    "print(\"Labels Shape:\", y.shape)\n",
    "print(\"Languages Shape:\", languages.shape)\n",
    "\n",
    "print(\"AI Samples:\", np.sum(y == 0))\n",
    "print(\"Human Samples:\", np.sum(y == 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "275ca08d-ca34-41dd-b932-5f3c776d263b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved to: ..\\artifacts\\features\\ML\n"
     ]
    }
   ],
   "source": [
    "FEATURE_DIR = Path(\"../artifacts/features/ML\")\n",
    "FEATURE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "np.save(FEATURE_DIR / \"X_features.npy\", X)\n",
    "np.save(FEATURE_DIR / \"y_labels.npy\", y)\n",
    "np.save(FEATURE_DIR / \"languages.npy\", languages)\n",
    "\n",
    "print(\"Features saved to:\", FEATURE_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (System)",
   "language": "python",
   "name": "systempy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
